{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alicia Sigmon\n",
    "\n",
    "als333@pitt.edu\n",
    "\n",
    "10/17/2017\n",
    "\n",
    "# Discourse Analysis of the Australian Radio Talkback Courpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the Corpus\n",
    "- The Australian Radio Talkback corpus contains raw text files of telephone conversations.\n",
    "- These conversations include the speaker's role (presenter, expert, or caller), name, and gender.\n",
    "- The conversations include other verbal cues such as laughter <laugh> and where a speaker says something during another speaker's turn <E1 yeah>. It also notes corrections to the transcription in squirrley brackets {}.\n",
    "\n",
    "#### Discourse Analysis Goals\n",
    "- commparing speakers by role and gender\n",
    "- aspects to consider:\n",
    "    - back channels (yeah, uhhu, that's great!)\n",
    "    - vocabulary size (avg word length)\n",
    "    - number of turns, sentences, and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the fileids for ART\n",
    "# Using PlaintextCorpusReader\n",
    "ART_corpus_root = r'C:\\Users\\sigmo\\Documents\\Data_Science\\Project-Alicia\\data_files\\AustralianRadioTalkback\\files\\Raw'\n",
    "ART_corpus = PlaintextCorpusReader(ART_corpus_root, '.*')\n",
    "\n",
    "ART_fids=[x for x in ART_corpus.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['ABCE1-raw.txt', 'ABCE2-raw.txt', 'ABCE3-raw.txt', 'ABCE4-raw.txt', 'ABCNE1-raw.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ART_fids)\n",
    "ART_fids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"[Presenter 1: Simon Marnie, M] Thanks for that John Hall now John Hall will be listening for the next hour 'cos Angus Stewart is here to take your calls eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two something in the garden that's causing you problems give us a call right now and Angus can I mean y'know he is known in the trade as Mr popergation {propagation} Mr propagation. He's also known for his passion for natives and his love of o orchids am I right so far.\\n\\n[Expert 1: Angus Stewart, M] I guess yeah yeah <laughs>.\\n\\n[P1] He's also known <E1 sounds reasonable> for his ability to open cosposting {composting} toilets so he can tell you anything worm farm problems certainly helped us and although I'm still confused about dry ingredients we might talk about that as well but eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two fine sunny day today top temperatures on the coast of twenty-seven inland thirty degrees Bowral enjoying twen\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ART_corpus.raw()[:1000]==ART_corpus.raw('ABCE1-raw.txt')[:1000]\n",
    "ART_corpus.raw()[:1000]\n",
    "# Each new line begins with the speaker in [] and ends with \\n\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[\"[Presenter 1: Simon Marnie, M] Thanks for that John Hall now John Hall will be listening for the next hour 'cos Angus Stewart is here to take your calls eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two something in the garden that's causing you problems give us a call right now and Angus can I mean y'know he is known in the trade as Mr popergation {propagation} Mr propagation. He's also known for his passion for natives and his love of o orchids am I right so far.\", '[Expert 1: Angus Stewart, M] I guess yeah yeah <laughs>.', \"[P1] He's also known <E1 sounds reasonable> for his ability to open cosposting {composting} toilets so he can tell you anything worm farm problems certainly helped us and although I'm still confused about dry ingredients we might talk about that as well but eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two fine sunny day today top temperatures on the coast of twenty-seven inland thirty degrees Bowral enjoying twen\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['[', 'Presenter', '1', ':', 'Simon', 'Marnie', ',', 'M', ']', 'Thanks', 'for', 'that', 'John', 'Hall', 'now', 'John', 'Hall', 'will', 'be', 'listening', 'for', 'the', 'next', 'hour', \"'cos\", 'Angus', 'Stewart', 'is', 'here', 'to', 'take', 'your', 'calls', 'eight-triple-three-one-thousand', 'one-eight-hundred-eight-hundred-seven-oh-two', 'something', 'in', 'the', 'garden', 'that', \"'s\", 'causing', 'you', 'problems', 'give', 'us', 'a', 'call', 'right', 'now', 'and', 'Angus', 'can', 'I', 'mean', \"y'know\", 'he', 'is', 'known', 'in', 'the', 'trade', 'as', 'Mr', 'popergation', '{', 'propagation', '}', 'Mr', 'propagation', '.', 'He', \"'s\", 'also', 'known', 'for', 'his', 'passion', 'for', 'natives', 'and', 'his', 'love', 'of', 'o', 'orchids', 'am', 'I', 'right', 'so', 'far', '.', '[', 'Expert', '1', ':', 'Angus', 'Stewart', ',', 'M', ']', 'I', 'guess', 'yeah', 'yeah', '<', 'laughs', '>', '.', '[', 'P1', ']', 'He', \"'s\", 'also', 'known', '<', 'E1', 'sounds', 'reasonable', '>', 'for', 'his', 'ability', 'to', 'open', 'cosposting', '{', 'composting', '}', 'toilets', 'so', 'he', 'can', 'tell', 'you', 'anything', 'worm', 'farm', 'problems', 'certainly', 'helped', 'us', 'and', 'although', 'I', \"'m\", 'still', 'confused', 'about', 'dry', 'ingredients', 'we', 'might', 'talk', 'about', 'that', 'as', 'well', 'but', 'eight-triple-three-one-thousand', 'one-eight-hundred-eight-hundred-seven-oh-two', 'fine', 'sunny', 'day', 'today', 'top', 'temperatures', 'on', 'the', 'coast', 'of', 'twenty-seven', 'inland', 'thirty', 'degrees', 'Bowral', 'enjoying', 'twen']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ART_corpus.raw()[:1000])\n",
    "\n",
    "mini=ART_corpus.raw()[:1000]\n",
    "# list split by speakers' lines\n",
    "mini_art=mini.split('\\n\\n')\n",
    "mini_art\n",
    "\n",
    "# 1st attempt at word tokenizing\n",
    "mini_words=nltk.word_tokenize(mini)\n",
    "mini_words\n",
    "    # this does not keep the information of the speaker within brackets as one token\n",
    "    # how can I separate this information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Presenter 1: Simon Marnie, M] Thanks for that John Hall now John Hall will be listening for the next hour 'cos Angus Stewart is here to take your calls eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two something in the garden that's causing you problems give us a call right now and Angus can I mean y'know he is known in the trade as Mr popergation {propagation} Mr propagation. He's also known for his passion for natives and his love of o orchids am I right so far.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presenter 1: Simon Marnie, M\n",
      "Thanks for that John Hall now John Hall will be listening for the next hour 'cos Angus Stewart is here to take your calls eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two something in the garden that's causing you problems give us a call right now and Angus can I mean y'know he is known in the trade as Mr popergation {propagation} Mr propagation. He's also known for his passion for natives and his love of o orchids am I right so far.\n"
     ]
    }
   ],
   "source": [
    "mini_art[0]\n",
    "endbrack = mini_art[0].index(']')\n",
    "print(mini_art[0][1:endbrack])\n",
    "print(mini_art[0][endbrack+2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating lists for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[Presenter 1: Simon Marnie, M] Thanks for that John Hall now John Hall will be listening for the next hour 'cos Angus Stewart is here to take your calls eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two something in the garden that's causing you problems give us a call right now and Angus can I mean y'know he is known in the trade as Mr popergation {propagation} Mr propagation. He's also known for his passion for natives and his love of o orchids am I right so far.\", '[Expert 1: Angus Stewart, M] I guess yeah yeah <laughs>.', \"[P1] He's also known <E1 sounds reasonable> for his ability to open cosposting {composting} toilets so he can tell you anything worm farm problems certainly helped us and although I'm still confused about dry ingredients we might talk about that as well but eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two fine sunny day today top temperatures on the coast of twenty-seven inland thirty degrees Bowral enjoying twenty-seven and Katoomba twenty-five degrees currently around town on the coast it's seventeen that's four below <,> r Richmond and Bankstown are fifteen degrees Penrith sixteen Katoomba thirteen and Gosford twelve. One of the jewels in the open garden scheme crown is opening today and this is just a garden to envy how would you like <,> to have <,> a beautiful sandstone cottage nestled underneath a waterfall with a little pond and then a creek that runs through with thousands of water dragons so tame they come up and just <,> kiss you. Would you like to live there.\", '[E1] Okay.', \"[P1] Jeanne Villani does and we'll find out the secret of her open garden and give you the address so that you can go along today and tomorrow to see Waterfall Cottage which is a part of the open garden scheme all this and more because it is Saturday.\\r\\n\\r\\n{program advert}\", \"[P1] Eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two Suzanne's on the line in McMahon's Point and.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting all lines\n",
    "ART_lines=ART_corpus.raw().split(\"\\n\\n\")\n",
    "ART_lines[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCE1-raw.txt\n",
      "ABCE2-raw.txt\n"
     ]
    }
   ],
   "source": [
    "for y in ART_fids[:2]:\n",
    "    print(y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the speaker information, text, and file name for each line\n",
    "# and storing them in individual lists\n",
    "\n",
    "# also counting the number of utterances per file to use as an index in art_df\n",
    "\n",
    "speaker=[]\n",
    "text=[]\n",
    "line_fid=[]\n",
    "utterance_num=[]\n",
    "\n",
    "for y in ART_fids:\n",
    "    count=0\n",
    "    \n",
    "    for x in ART_corpus.raw(y).split(\"\\n\\n\"):\n",
    "        count+=1\n",
    "            \n",
    "        if x.startswith(\"[\"):\n",
    "            endbrack = x.index(']')\n",
    "            line_fid.append(y)\n",
    "            speaker.append(x[1:endbrack])\n",
    "            text.append(x[endbrack+2:])\n",
    "            utterance_num.append(count)\n",
    "\n",
    "# text[3093]   # this line is actually 2 lines!! E1 and C4!\n",
    "# line_fid[3093] # COME3\n",
    "\n",
    "\n",
    "\n",
    "# This was attempted inside the 2nd for loop above to fix the line with the index 3093\n",
    "# in order to fix the line shown above because [C4]'s line is contianed within [E1]'s line\n",
    "    # there will be a better way to do this\n",
    "\n",
    "# if count == 3093:\n",
    "#     sent = \"[E1] That sounds exactly <C4 inaudible> what it is just because you've had a hernia operation uh any sort of operation gall bladder operation hernia operation <,> doesn't mean that you can't get other things wrong with you and you still do you still get tonsillitis you still <C4 yeah> get appendicitis and you can still get gastroenteritis which sounds like what you've got.\\r\\n\\r\\n[C4] Nah <E1 it ih thi> and because of the operation that's stirring the my tummy up.\"\n",
    "#     sent.split(\"\\r\\n\\r\\n\")\n",
    "#     for item in new_split:\n",
    "#         endbrack = x.index(']')\n",
    "#         line_fid.append(y)\n",
    "#         speaker.append(x[1:endbrack])\n",
    "#         text.append(x[endbrack+2:])\n",
    "#         utterance_num.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Presenter 1: Simon Marnie, M', 'Expert 1: Angus Stewart, M', 'P1', 'E1', 'P1', 'P1', 'Caller 1: Suzanne, F', 'P1', 'C1', 'P1']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[\"Thanks for that John Hall now John Hall will be listening for the next hour 'cos Angus Stewart is here to take your calls eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two something in the garden that's causing you problems give us a call right now and Angus can I mean y'know he is known in the trade as Mr popergation {propagation} Mr propagation. He's also known for his passion for natives and his love of o orchids am I right so far.\", 'I guess yeah yeah <laughs>.', \"He's also known <E1 sounds reasonable> for his ability to open cosposting {composting} toilets so he can tell you anything worm farm problems certainly helped us and although I'm still confused about dry ingredients we might talk about that as well but eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two fine sunny day today top temperatures on the coast of twenty-seven inland thirty degrees Bowral enjoying twenty-seven and Katoomba twenty-five degrees currently around town on the coast it's seventeen that's four below <,> r Richmond and Bankstown are fifteen degrees Penrith sixteen Katoomba thirteen and Gosford twelve. One of the jewels in the open garden scheme crown is opening today and this is just a garden to envy how would you like <,> to have <,> a beautiful sandstone cottage nestled underneath a waterfall with a little pond and then a creek that runs through with thousands of water dragons so tame they come up and just <,> kiss you. Would you like to live there.\", 'Okay.', \"Jeanne Villani does and we'll find out the secret of her open garden and give you the address so that you can go along today and tomorrow to see Waterfall Cottage which is a part of the open garden scheme all this and more because it is Saturday.\\r\\n\\r\\n{program advert}\", \"Eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two Suzanne's on the line in McMahon's Point and.\", 'Hello.', 'How are you.', \"I'm good thank you.\", \"You've got a big fat <C1 laughs> Morton Bay fig.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the lists\n",
    "len(line_fid)\n",
    "line_fid[:10]\n",
    "line_fid[-10:]\n",
    "\n",
    "len(speaker)\n",
    "speaker[:10]\n",
    "\n",
    "len(text)\n",
    "text[:10]\n",
    "\n",
    "len(utterance_num)\n",
    "utterance_num[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker information compiled\n",
    "speaker_infos=[]\n",
    "speaker_infos_fid=[]\n",
    "count=0\n",
    "for x in speaker:\n",
    "    y=line_fid[count] # trying to fix duplicates\n",
    "    count+=1\n",
    "    if len(x)>5:\n",
    "        speaker_infos.append(x)\n",
    "        speaker_infos_fid.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Presenter 1: Simon Marnie, M', 'Expert 1: Angus Stewart, M', 'Caller 1: Suzanne, F', 'Caller 2: Lisa, F', 'Caller 3: Sally, F', 'Caller 4: Danny, M', 'Caller 5: Trevor, M', 'Caller 6: Gillian, F', 'Caller 7: Colleen, F', 'Caller 8: Bernie, M', 'Caller 9: William, M', 'Expert 2: Jeanne Villani, F', 'Caller 10: Beth, F', 'Caller 11: Lynne, F', 'Caller 12: Jack, M', 'Presenter 1: Simon Marnie, M', 'Expert 1: Les, M', 'Expert 2: Pete, M', 'Caller 1: Julie, F', 'Caller 2: Janelle, F']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE2-raw.txt', 'ABCE2-raw.txt', 'ABCE2-raw.txt', 'ABCE2-raw.txt', 'ABCE2-raw.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speaker_infos)\n",
    "speaker_infos[:20]\n",
    "\n",
    "len(speaker_infos_fid)\n",
    "speaker_infos_fid[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presenter 1: Simon Marnie, M\n",
      "0\n",
      "Presenter 1: Simon Marnie, M\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ABCE1-raw.txt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ABCE2-raw.txt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simon marnie is presenter 1 for both files ABCE1 and ABCE2\n",
    "count=0\n",
    "for x in speaker_infos:\n",
    "    if \"Simon Marnie\" in x:\n",
    "        print(x) # he's only in those 2 files! \n",
    "        print(count)\n",
    "    count+=1\n",
    "\n",
    "speaker_infos_fid[0]\n",
    "speaker_infos_fid[15] # shows he's in dif files <-- will work on fixing once all speaker info is in the same format!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Caller 11, Robyn, F'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1478"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 23, Maureen, F'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2699"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 9 Maureen, F'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3172"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'P1b Paul Murray, M'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4483"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 12, Brian, M'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8600"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 10, Brett, M'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8858"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding formats missing the :\n",
    "for x in speaker_infos:\n",
    "    if \":\" not in x:\n",
    "        x\n",
    "        speaker_infos.index(x)\n",
    "        speaker.index(x)\n",
    "\n",
    "# what's happening with Paul?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4483"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['C24', 'P2', 'C24', 'P2', 'C24', 'P2', 'C24', 'P2', 'C24', 'P2', 'C24', 'P2', 'C24', 'P2', 'C24', 'P2', 'C24', 'P2', 'C24', 'P2', 'C24', 'P2', 'C24', 'P1', 'P2', 'C24', 'P1', 'C24', 'P2', 'C24', 'P2', 'P1', 'P2', 'P1', 'P2', 'P1', 'Presenter 1: Paul Murray, M', 'Caller 1: Ella, F', 'P1a', 'C1', 'P1a', 'C1', 'P1a', 'C1', 'P1a', 'Caller 2: TJ, M', 'P1a', 'C2', 'P1a', 'C2', 'P1a', 'Caller 3: Jo, F', 'P1a', 'C3', 'P1a', 'C3', 'P1a', 'C3', 'P1a', 'C3', 'P1a', 'Caller 4: Ruben, M', 'P1a', 'C4', 'P1a', 'C4', 'P1a', 'Caller 5: Johnny, M', 'P1a', 'C5', 'P1a', 'Caller 6: LJ, M', 'P1a', 'C6', 'P1a', 'C6', 'P1a', 'C6', 'P1a', 'C6', 'P1a', 'C6', 'P1a', 'P1b Paul Murray, M', 'Caller 7: Megan, F', 'P1b', 'C7', 'P1b', 'C7', 'P1b', 'C7', 'P1b', 'C7', 'P1b', 'C7', 'P1b', 'C7', 'P1b', 'C7', 'P1b']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4436"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'COME6-raw.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining file COME6-raw.txt\n",
    "speaker.index('P1b Paul Murray, M') # 4483\n",
    "speaker[4400:4500]\n",
    "\n",
    "speaker.index('Presenter 1: Paul Murray, M') # 4436\n",
    "line_fid[4436] #COME6-raw.txt\n",
    "\n",
    "# after looking at this file, I think it needs to be removed!!\n",
    "    # The document switches back and forth between P1a and P1b, and once P1a had an interruption in P1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually adding the colon for first time info \n",
    "speaker_infos[40]='Caller 11: Robyn, F'\n",
    "speaker_infos[98]='Caller 23: Maureen, F'\n",
    "speaker_infos[121]='Caller 9: Maureen, F'\n",
    "speaker_infos[168]='Presenter 1b: Paul Murray, M' # probably deleting file\n",
    "speaker_infos[408]='Caller 12: Brian, M'\n",
    "speaker_infos[420]='Caller 10: Brett, M'\n",
    "\n",
    "speaker[1478]='Caller 11: Robyn, F'\n",
    "speaker[2699]='Caller 23: Maureen, F'\n",
    "speaker[3172]='Caller 9: Maureen, F'\n",
    "speaker[4483]='Presenter 1b: Paul Murray, M' # maybe delete this file\n",
    "speaker[8600]='Caller 12: Brian, M'\n",
    "speaker[8858]='Caller 10: Brett, M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using word_tokenize to separate out speaker info\n",
    "speaker_toks=[]\n",
    "for x in speaker:\n",
    "    if len(x) > 5:\n",
    "        speaker_toks.append(nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Presenter', '1', ':', 'Simon', 'Marnie', ',', 'M'], ['Expert', '1', ':', 'Angus', 'Stewart', ',', 'M'], ['Caller', '1', ':', 'Suzanne', ',', 'F'], ['Caller', '2', ':', 'Lisa', ',', 'F'], ['Caller', '3', ':', 'Sally', ',', 'F'], ['Caller', '4', ':', 'Danny', ',', 'M'], ['Caller', '5', ':', 'Trevor', ',', 'M'], ['Caller', '6', ':', 'Gillian', ',', 'F'], ['Caller', '7', ':', 'Colleen', ',', 'F'], ['Caller', '8', ':', 'Bernie', ',', 'M'], ['Caller', '9', ':', 'William', ',', 'M'], ['Expert', '2', ':', 'Jeanne', 'Villani', ',', 'F'], ['Caller', '10', ':', 'Beth', ',', 'F'], ['Caller', '11', ':', 'Lynne', ',', 'F'], ['Caller', '12', ':', 'Jack', ',', 'M'], ['Presenter', '1', ':', 'Simon', 'Marnie', ',', 'M'], ['Expert', '1', ':', 'Les', ',', 'M'], ['Expert', '2', ':', 'Pete', ',', 'M'], ['Caller', '1', ':', 'Julie', ',', 'F'], ['Caller', '2', ':', 'Janelle', ',', 'F'], ['Caller', '3', ':', 'Geoff', ',', 'M'], ['Caller', '4', ':', 'Terry', ',', 'M'], ['Expert', '3', ':', 'John', 'Hall', ',', 'M'], ['Caller', '5', ':', 'Judy', ',', 'F'], ['Caller', '6', ':', 'Dawn', ',', 'F'], ['Caller', '7', ':', 'Paul', ',', 'M'], ['Caller', '8', ':', 'Linda', ',', 'F'], ['Caller', '9', ':', 'Croydon', ',', 'M'], ['Caller', '10', ':', 'Joan', ',', 'F'], ['Presenter', '1', ':', 'Lynne', 'Haultain', ',', 'F'], ['Presenter', '2', ':', 'Jurate', 'Sasnaitis', ',', 'F'], ['Caller', '1', ':', 'Rick', ',', 'M'], ['Caller', '2', ':', 'Sarah', ',', 'F'], ['Caller', '3', ':', 'Liz', ',', 'F'], ['Caller', '4', ':', 'Cathy', ',', 'F'], ['Caller', '6', ':', 'Bullia', ',', 'F'], ['Caller', '7', ':', 'Juliet', ',', 'F'], ['Caller', '8', ':', 'Melanie', ',', 'F'], ['Caller', '9', ':', 'Margaret', ',', 'F'], ['Caller', '10', ':', 'Lisa', ',', 'F'], ['Caller', '11', ':', 'Robyn', ',', 'F'], ['Caller', '12', ':', 'Mary', ',', 'F'], ['Expert', '1', ':', 'Ric', 'Nattrass', ',', 'M'], ['Presenter', '1', ':', 'Kelly', 'Higgins-Devine', ',', 'F'], ['Caller', '1', ':', 'Graham', ',', 'M'], ['Caller', '2', ':', 'Len', ',', 'M'], ['Caller', '3', ':', 'Cathy', ',', 'F'], ['Caller', '4', ':', 'Margaret', ',', 'F'], ['Caller', '5', ':', 'Hayden', ',', 'M'], ['Caller', '6', ':', 'Alan', ',', 'M'], ['Caller', '7', ':', 'Sharon', ',', 'F'], ['Presenter', '1', ':', 'Trevor', 'Jackson', ',', 'M'], ['Expert', '1', ':', 'Roly', 'Sussex', ',', 'M'], ['Caller', '1', ':', 'Barry', ',', 'M'], ['Caller', '2', ':', 'Anne', ',', 'F'], ['Caller', '3', ':', 'Lance', ',', 'M'], ['Caller', '4', ':', 'Pauline', ',', 'F'], ['Caller', '5', ':', 'John', ',', 'M'], ['Caller', '6', ':', 'Alan', ',', 'M'], ['Caller', '7', ':', 'Colin', ',', 'M'], ['Caller', '8', ':', 'Roger', ',', 'M'], ['Caller', '9', ':', 'Jim', ',', 'M'], ['Presenter', '1', ':', 'Trevor', 'Jackson', ',', 'M'], ['Expert', '1', ':', 'Greg', 'Kerrin', ',', 'M'], ['Caller', '1', ':', 'Graham', ',', 'M'], ['Caller', '2', ':', 'Patricia', ',', 'F'], ['Caller', '3', ':', 'John', ',', 'M'], ['Caller', '4', ':', 'Iris', ',', 'F'], ['Caller', '5', ':', 'Peter', ',', 'M'], ['Caller', '6', ':', 'Kath', ',', 'F'], ['Caller', '7', ':', 'Leon', ',', 'M'], ['Caller', '8', ':', 'Bill', ',', 'M'], ['Caller', '9', ':', 'Iris', ',', 'F'], ['Presenter', '1', ':', 'Luke', 'Bona', ',', 'M'], ['Expert', '1', ':', 'Linda', 'Ross', ',', 'F'], ['Caller', '1', ':', 'Anne', ',', 'F'], ['Caller', '2', ':', 'Iris', ',', 'F'], ['Caller', '3', ':', 'Greg', ',', 'M'], ['Caller', '4', ':', 'Jenny', ',', 'F'], ['Caller', '5', ':', 'Mila', ',', 'F'], ['Caller', '6', ':', 'Pamela', ',', 'F'], ['Caller', '7', ':', 'Glad', ',', 'F'], ['Caller', '8', ':', 'Sally', ',', 'F'], ['Caller', '9', ':', 'John', ',', 'M'], ['Caller', '10', ':', 'Dorothy', ',', 'F'], ['Caller', '11', ':', 'Nora', ',', 'F'], ['Caller', '12', ':', 'Dorothy', ',', 'F'], ['Caller', '13', ':', 'Laurie', ',', 'F'], ['Caller', '14', ':', 'Nicky', ',', 'F'], ['Caller', '15', ':', 'Maurice', ',', 'M'], ['Caller', '16', ':', 'Robyn', ',', 'F'], ['Caller', '17', ':', 'Winifred', ',', 'F'], ['Expert', '2', ':', 'Rodian', 'Booker', ',', 'M'], ['Caller', '18', ':', 'Noel', ',', 'M'], ['Caller', '19', ':', 'Nicky', ',', 'F'], ['Caller', '20', ':', 'Anita', ',', 'F'], ['Caller', '21', ':', 'Lorraine', ',', 'F'], ['Caller', '22', ':', 'Judy', ',', 'F'], ['Caller', '23', ':', 'Maureen', ',', 'F'], ['Presenter', '1', ':', 'Luke', 'Bona', ',', 'M']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# speaker_toks['Caller', '33','b',':', 'Chris',',','male']\n",
    "speaker_toks[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[['Presenter', '1', ':', 'Simon', 'Marnie', ',', 'M'], ['Expert', '1', ':', 'Angus', 'Stewart', ',', 'M'], ['Caller', '1', ':', 'Suzanne', ',', 'F'], ['Caller', '2', ':', 'Lisa', ',', 'F'], ['Caller', '3', ':', 'Sally', ',', 'F']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # NOT A GOOD METHOD! only a good method for type\n",
    "\n",
    "# # getting gender, type, and number\n",
    "len(speaker_toks)\n",
    "speaker_toks[:5]\n",
    "# gen=[x[-1] for x in speaker_toks]\n",
    "speaker_type=[x[0][:1] for x in speaker_toks]\n",
    "\n",
    "len(speaker_type)\n",
    "# len(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert 1: Doctor Graham\n",
      "111\n",
      "Caller 33b: Chris, male\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "for x in speaker_infos:\n",
    "    if x[-1:] != \"F\" and x[-1:] != \"M\":\n",
    "        print(x)\n",
    "        print(speaker_infos.index(x))\n",
    "        \n",
    "# Graham's gender: \"\" -> \"NaN\"\n",
    "# Chris's gender: \"male\" -> \"M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2967"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7659"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Expert 1: Doctor Graham'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 33b: Chris, male'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker.index(\"Expert 1: Doctor Graham\")\n",
    "speaker.index(\"Caller 33b: Chris, male\")\n",
    "\n",
    "speaker[2967]\n",
    "speaker[7659]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_infos[111] = \"Expert 1: Doctor Graham, NAN\"\n",
    "speaker_infos[359] = \"Caller 33b: Chris, M\"\n",
    "\n",
    "speaker[2967] = \"Expert 1: Doctor Graham, NAN\"\n",
    "speaker[7659] = \"Caller 33b: Chris, M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Expert 1: Doctor Graham, NAN'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 33b: Chris, M'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Expert 1: Doctor Graham, NAN'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 33b: Chris, M'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correctly adjusted the incorrect gender formats for Graham and Chris!!\n",
    "\n",
    "speaker_infos[111]\n",
    "speaker_infos[359]\n",
    "\n",
    "speaker[2967]\n",
    "speaker[7659]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen\n",
    "\n",
    "# # fixing Graham\n",
    "# speaker_infos[gen.index(\"Graham\")] # does not list a gender\n",
    "# gen[gen.index(\"Graham\")]=\"NAN\"\n",
    "\n",
    "# # fixing \"male\" for gender IN speaker_infos AND speaker\n",
    "# speaker_infos[gen.index(\"male\")]\n",
    "# speaker_infos[gen.index(\"male\")]='Caller 33b: Chris, M'\n",
    "# print(\"index of 'male':\",str(gen.index(\"male\")))\n",
    "\n",
    "# # this claims chris is an Expert - WRONG \n",
    "# speaker[gen.index(\"male\")]\n",
    "\n",
    "# len(gen)\n",
    "# len(speaker)\n",
    "# len(speaker_infos)\n",
    "\n",
    "# # CANNOT DO THIS BECAUSE SPEAKER'S INDEX IS NOT THE SAME AS GEN'S INDEX\n",
    "# # speaker[gen.index(\"male\")]='Caller 33b: Chris, M'       \n",
    "#     # THIS IS WHY 33B WAS IN ABCE1!!!! \n",
    "\n",
    "# speaker[speaker.index('Caller 33b: Chris, male')]='Caller 33b: Chris, M'\n",
    "# speaker_infos[gen.index(\"male\")]\n",
    "\n",
    "# gen[gen.index(\"male\")]='M'\n",
    "# gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker_infos.index('Caller 33b: Chris, M') # 359\n",
    "# speaker.index('Caller 33b: Chris, M') # 7659\n",
    "\n",
    "# speaker_num\n",
    "\n",
    "# line_fid[359]\n",
    "# line_fid[7659]\n",
    "\n",
    "\n",
    "# speaker_infos[:20]\n",
    "# speaker_num[:20]\n",
    "\n",
    "# # used to see a \":\" as the number for Jenny, Caller 5\n",
    "#     # ex: Jenny's first line is called \"C5\" instead of Caller 5\n",
    "#     # see below for fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # which speaker_num items are wrong?\n",
    "# count=0\n",
    "# for x in speaker_num:\n",
    "#     if x == \":\":\n",
    "#         print(x)\n",
    "#         speaker_infos[count]\n",
    "#         print(count)\n",
    "#     count+=1\n",
    "    \n",
    "# # later rebuild speaker_num using regex\n",
    "# # to find these where the 1st instance uses C,E,or P instead of Caller, Expert etc, can use .startswith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C5: Jenny, F\n",
      "105\n",
      "C14: Noelene, F\n",
      "244\n"
     ]
    }
   ],
   "source": [
    "# speakers whose words are not written out!\n",
    "\n",
    "for x in speaker_infos:\n",
    "    if x[2].isalpha()== False:\n",
    "        print(x)\n",
    "        print(speaker_infos.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2834"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6063"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixing the above lines that labeled the number as a colon\n",
    "\n",
    "# speaker_num[105] = '5'\n",
    "# speaker_num[244] = '14'\n",
    "\n",
    "# Fixing Jenny and Noelene!!\n",
    "speaker_infos[105]='Caller 5: Jenny, F'\n",
    "speaker_infos[244]='Caller 14: Noelene, F'\n",
    "\n",
    "speaker.index('C5: Jenny, F') # 2834\n",
    "speaker.index('C14: Noelene, F') # 6063\n",
    "\n",
    "speaker[2834] = 'Caller 5: Jenny, F'\n",
    "speaker[6063] = 'Caller 14: Noelene, F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Caller 5: Jenny, F'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 14: Noelene, F'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 5: Jenny, F'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Caller 14: Noelene, F'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jenny and Noelene are fixed!\n",
    "\n",
    "speaker_infos[105]\n",
    "speaker_infos[244]\n",
    "\n",
    "speaker[2834]\n",
    "speaker[6063]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dictionary for gender of the speaker from speaker info\n",
    "# gen_dict={x:x[-1] for x in speaker_infos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_dict['Presenter 1: Simon Marnie, M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dictionary for filename from speaker info\n",
    "# file_speaker_dict={x:line_fid[speaker.index(x)] for x in speaker_infos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_speaker_dict['Presenter 1: Simon Marnie, M']\n",
    "# file_speaker_dict['Caller 12: Brian, M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dictionary for speaker's filename, gender, and shortcut label (ex: P1, C12, etc..)\n",
    "# gen_file_speaker_dict={x:[line_fid[speaker.index(x)],x[-1],speaker_type[speaker_infos.index(x)]+speaker_num[speaker_infos.index(x)]] for x in speaker_infos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_file_speaker_dict['Presenter 1: Simon Marnie, M']\n",
    "# gen_file_speaker_dict['Caller 12: Brian, M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33b'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figuring out how to do the regular expression to find the speaker_number\n",
    "# USE x IN THE BIG LOOP\n",
    "import re\n",
    "\n",
    "s=\"Presenter 1: Simon Marnie, M\"\n",
    "s=\"Caller 33b: Chris, M\"\n",
    "\n",
    "re.findall('\\d+[a-z]*', s)[0]\n",
    "\n",
    "\n",
    "# I have now commented out the speaker number list -- working on removing it now!!\n",
    "# I can fix the speaker number list later by doing the above method! I can also potentially delete that list? superfluous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using regular expressions to find the speaker num!\n",
    "for x in speaker_infos:\n",
    "    speaker_num=[re.findall('\\d+[a-z]*', x)[0] for x in speaker_infos]\n",
    "    \n",
    "len(speaker_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAT4-P1\n",
      "NAT4-C1\n",
      "NAT4-C2\n",
      "NAT4-C3\n",
      "NAT4-C4\n",
      "NAT4-C5\n",
      "NAT4-C6\n"
     ]
    }
   ],
   "source": [
    "# creating a lists for all speakers and unique speakers\n",
    "\n",
    "new_speaker_list=[]    # a list of each line's speaker with the filename\n",
    "all_speaker_type=[]    # a list of each line's speaker's P/C/E designation\n",
    "unique_speaker=[]      # a list of each speaker's unique id (ex: ABCE1-P1)\n",
    "unique_speaker_type=[] # a list of each unique speaker's type (P/C/E)\n",
    "unique_speaker_fid=[]  # a list of which file contains each unique speaker\n",
    "\n",
    "count = 0 \n",
    "all_count=0\n",
    "\n",
    "used_speaker=[]\n",
    "\n",
    "# for x in speaker[:500]:\n",
    "for x in speaker:\n",
    "    \n",
    "    x_loc=speaker.index(x)\n",
    "#     print(line_fid[x_loc])\n",
    "#     print(line_fid[x_loc].index(\"-\"))\n",
    "#     print(line_fid[x_loc][:dash+1])\n",
    "    dash=line_fid[x_loc].index(\"-\")\n",
    "    \n",
    "    \n",
    "    # adjusts for people like Simon Marnie who show up in multiple files (ABCE1 and ABCE2)\n",
    "    if x in used_speaker:\n",
    "        x_loc=all_count\n",
    "        dash=line_fid[all_count].index(\"-\")\n",
    "    \n",
    "    if x in speaker_infos:\n",
    "        \n",
    "#         print(speaker_type[speaker_infos.index(x)])\n",
    "#         print(speaker_num[speaker_infos.index(x)])\n",
    "#         print(line_fid[x_loc][:dash+1])\n",
    "\n",
    "        current_speaker=speaker_infos[count]\n",
    "        new_speaker_list.append(line_fid[x_loc][:dash+1]+speaker_type[speaker_infos.index(x)]+speaker_num[speaker_infos.index(x)])\n",
    "        all_speaker_type.append(speaker_type[speaker_infos.index(x)])\n",
    "        \n",
    "        # ONLY CHECK THESE IF YOU LIMIT THE RANGE OF speaker!\n",
    "#         print(line_fid[x_loc][:dash+1]) # CORRECT\n",
    "#         print(speaker_type[count]) # GIVES WRONG LETTER -- CANNOT USE COUNT FEATURE\n",
    "#         print(x[0])\n",
    "#         print(x+\"\\n\") # correctly identifies Marnie's second occurance as being in ABCE2\n",
    "\n",
    "        NUM=re.findall('\\d+[a-z]*', x) # need regex to fix the number - get type from first letter of x instead of using speaker_type list\n",
    "        \n",
    "        \n",
    "        # NAT4 Duplicate Loop:\n",
    "            # DUPLICATES: File NAT4 begins with a new Presenter 1, Caller1-6 at the end of the file!!\n",
    "        if line_fid[x_loc][:dash+1]+x[0]+NUM[0] in unique_speaker:\n",
    "            \n",
    "            print(line_fid[x_loc][:dash+1]+x[0]+NUM[0])\n",
    "                # The second half of NAT4 will now be NAT4.5\n",
    "                \n",
    "            unique_speaker.append(line_fid[x_loc][:dash]+\".5\"+line_fid[x_loc][dash-1:dash+1]+x[0]+NUM[0])\n",
    "            unique_speaker_type.append(x[0])\n",
    "            unique_speaker_fid.append(line_fid[x_loc][:dash]+\".5\"+line_fid[x_loc][dash-1:dash+1])\n",
    "            \n",
    "        else:\n",
    "            unique_speaker.append(line_fid[x_loc][:dash+1]+x[0]+NUM[0])\n",
    "            unique_speaker_type.append(x[0])\n",
    "            unique_speaker_fid.append(line_fid[x_loc][:dash+1]) # refers to their first line to find the file id\n",
    "        \n",
    "        \n",
    "        count+=1\n",
    "        used_speaker.append(x)\n",
    "    else:\n",
    "        new_speaker_list.append(line_fid[x_loc][:dash+1]+x)\n",
    "        all_speaker_type.append(x[0]) # only want the letter\n",
    "    \n",
    "    all_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_speaker)\n",
    "len(unique_speaker) # 428\n",
    "\n",
    "# After adding the NAT4 Duplicate Loop, every speaker has a unique ID:\n",
    "len(set(unique_speaker)) # 421 -> 428 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First instance of Simon Marnie: Presenter 1: Simon Marnie, M , ABCE1-raw.txt\n",
      "Second instance of Simon Marnie: Presenter 1: Simon Marnie, M , ABCE2-raw.txt\n"
     ]
    }
   ],
   "source": [
    "# how many times is Simon Marnie the main presenter? Answer: twice!\n",
    "count=0\n",
    "for x in speaker:\n",
    "    if x == \"Presenter 1: Simon Marnie, M\":\n",
    "        count\n",
    "    count+=1\n",
    "print(\"First instance of Simon Marnie:\",str(speaker[0]), \",\", str(line_fid[0]))\n",
    "print(\"Second instance of Simon Marnie:\",str(speaker[471]), \",\", str(line_fid[471]))\n",
    "\n",
    "# line_fid WAS correctly built (at least where Simon Marnie is concnered)\n",
    "    # Simon is in ABCE1 and ABCE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9026"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9026"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9026"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original list of speakers for each line:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Presenter 1: Simon Marnie, M', 'Expert 1: Angus Stewart, M', 'P1', 'E1', 'P1', 'P1', 'Caller 1: Suzanne, F', 'P1', 'C1', 'P1', 'C1', 'P1', 'C1', 'P1', 'C1', 'P1', 'E1', 'C1', 'E1', 'C1', 'E1', 'C1', 'E1', 'C1', 'E1', 'C1', 'E1', 'C1', 'E1', 'C1', 'E1', 'C1', 'E1', 'C1', 'E1', 'C1', 'P1', 'C1', 'P1', 'C1', 'P1', 'E1', 'P1', 'E1', 'P1', 'E1', 'P1', 'E1', 'P1', 'E1', 'P1', 'E1', 'P1', 'P1', 'Caller 2: Lisa, F', 'P1', 'C2', 'P1', 'C2', 'E1', 'C2', 'E1', 'P1', 'C2', 'P1', 'C2', 'P1', 'E1', 'C2', 'E1', 'C2', 'E1', 'C2', 'E1', 'P1', 'E1', 'C2', 'P1', 'C2', 'E1', 'P1', 'C2', 'P1', 'C2', 'P1', 'P1', 'Caller 3: Sally, F', 'P1', 'C3', 'P1', 'C3', 'P1', 'C3', 'E1', 'C3', 'P1', 'C3', 'P1', 'E1', 'P1']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['P1', 'C13', 'P1', 'C13', 'P1', 'C13', 'P1', 'C13', 'P1', 'C13', 'P1', 'C13', 'P1', 'C13', 'P1', 'C13', 'P1', 'Caller 14: Ted, M', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'C14', 'P1', 'P1', 'P1', 'Caller 15: Britney, F', 'P1', 'C15', 'P1', 'C15', 'P1', 'C15', 'P1', 'C15', 'P1', 'C15', 'P1', 'C15', 'P1', 'C15', 'P1', 'Caller 16: Jesse, M', 'P1', 'C16', 'P1', 'C16', 'P1', 'C16', 'P1', 'C16', 'P1', 'C16', 'P1', 'C16', 'P1', 'Caller 17: Kieran, M', 'P1', 'C17']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New list of speakers for each line:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ABCE1-P1', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-P1', 'ABCE1-C1', 'ABCE1-P1', 'ABCE1-C1', 'ABCE1-P1', 'ABCE1-C1', 'ABCE1-P1', 'ABCE1-C1', 'ABCE1-P1', 'ABCE1-C1', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-E1', 'ABCE1-C1', 'ABCE1-P1', 'ABCE1-C1', 'ABCE1-P1', 'ABCE1-C1', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-P1', 'ABCE1-C2', 'ABCE1-P1', 'ABCE1-C2', 'ABCE1-P1', 'ABCE1-C2', 'ABCE1-E1', 'ABCE1-C2', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-C2', 'ABCE1-P1', 'ABCE1-C2', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-C2', 'ABCE1-E1', 'ABCE1-C2', 'ABCE1-E1', 'ABCE1-C2', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-C2', 'ABCE1-P1', 'ABCE1-C2', 'ABCE1-E1', 'ABCE1-P1', 'ABCE1-C2', 'ABCE1-P1', 'ABCE1-C2', 'ABCE1-P1', 'ABCE1-P1', 'ABCE1-C3', 'ABCE1-P1', 'ABCE1-C3', 'ABCE1-P1', 'ABCE1-C3', 'ABCE1-P1', 'ABCE1-C3', 'ABCE1-E1', 'ABCE1-C3', 'ABCE1-P1', 'ABCE1-C3', 'ABCE1-P1', 'ABCE1-E1', 'ABCE1-P1']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['ABCE1-P1', 'COME1-C13', 'ABCE1-P1', 'COME1-C13', 'ABCE1-P1', 'COME1-C13', 'ABCE1-P1', 'COME1-C13', 'ABCE1-P1', 'COME1-C13', 'ABCE1-P1', 'COME1-C13', 'ABCE1-P1', 'COME1-C13', 'ABCE1-P1', 'COME1-C13', 'ABCE1-P1', 'NAT8-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'COME1-C14', 'ABCE1-P1', 'ABCE1-P1', 'ABCE1-P1', 'NAT8-C15', 'ABCE1-P1', 'COME1-C15', 'ABCE1-P1', 'COME1-C15', 'ABCE1-P1', 'COME1-C15', 'ABCE1-P1', 'COME1-C15', 'ABCE1-P1', 'COME1-C15', 'ABCE1-P1', 'COME1-C15', 'ABCE1-P1', 'COME1-C15', 'ABCE1-P1', 'NAT8-C16', 'ABCE1-P1', 'COME1-C16', 'ABCE1-P1', 'COME1-C16', 'ABCE1-P1', 'COME1-C16', 'ABCE1-P1', 'COME1-C16', 'ABCE1-P1', 'COME1-C16', 'ABCE1-P1', 'COME1-C16', 'ABCE1-P1', 'NAT8-C17', 'ABCE1-P1', 'COME1-C17']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of the type of speaker for each line:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['P', 'E', 'P', 'E', 'P', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'E', 'C', 'E', 'C', 'E', 'C', 'E', 'C', 'E', 'C', 'E', 'C', 'E', 'C', 'E', 'C', 'E', 'C', 'E', 'C', 'P', 'C', 'P', 'C', 'P', 'E', 'P', 'E', 'P', 'E', 'P', 'E', 'P', 'E', 'P', 'E', 'P', 'P', 'C', 'P', 'C', 'P', 'C', 'E', 'C', 'E', 'P', 'C', 'P', 'C', 'P', 'E', 'C', 'E', 'C', 'E', 'C', 'E', 'P', 'E', 'C', 'P', 'C', 'E', 'P', 'C', 'P', 'C', 'P', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'E', 'C', 'P', 'C', 'P', 'E', 'P']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'P', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C', 'P', 'C']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of fileid for each line:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt', 'ABCE1-raw.txt']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt', 'NAT8-raw.txt']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing new_speaker_list, speaker, and all_speaker_type to make sure they are the same\n",
    "\n",
    "# 9026 lines\n",
    "len(new_speaker_list)\n",
    "len(speaker)\n",
    "len(all_speaker_type)\n",
    "\n",
    "print(\"Original list of speakers for each line:\")\n",
    "speaker[:100]\n",
    "speaker[-100:]\n",
    "\n",
    "print(\"New list of speakers for each line:\")\n",
    "new_speaker_list[:100]\n",
    "new_speaker_list[-100:]\n",
    "\n",
    "print(\"List of the type of speaker for each line:\")\n",
    "all_speaker_type[:100]\n",
    "all_speaker_type[-100:]\n",
    "\n",
    "print(\"List of fileid for each line:\")\n",
    "line_fid[:100]\n",
    "line_fid[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking unique_speaker, unique_speaker_type, and unique_speaker_fid\n",
    "\n",
    "# 428 for each\n",
    "len(speaker_infos)\n",
    "len(unique_speaker)\n",
    "len(unique_speaker_type)\n",
    "len(unique_speaker_fid)\n",
    "\n",
    "print(\"Speaker Infos:\")\n",
    "speaker_infos[:100]\n",
    "speaker_infos[-100:]\n",
    "\n",
    "print(\"Unique Speaker ID:\")\n",
    "unique_speaker[:100]\n",
    "unique_speaker[-100:]\n",
    "\n",
    "print(\"Unique Speaker Type:\")\n",
    "unique_speaker_type[:100] # Note: NOT made from speaker_type\n",
    "unique_speaker_type[-100:]\n",
    "\n",
    "print(\"unique Speaker Fileid:\")\n",
    "unique_speaker_fid[:100]\n",
    "unique_speaker_fid[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Marnie in the new lists:\n",
    "\n",
    "# marnie should be ABCE2\n",
    "speaker_infos[15]\n",
    "print(\"Marnie's 2ND file Unique ID:\", str(unique_speaker[15]))\n",
    "print(\"Marnie's speaker type:\",str(unique_speaker_type[15]))\n",
    "print(\"Marnie's fileid:\",str(unique_speaker_fid[15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding extra items in the text like laughter and interruptions\n",
    "\n",
    "# THIS IS A WORK IN PROGRESS\n",
    "# I will change my methods to use regular expressions in order to find backchannels instead of using all of these loops\n",
    "\n",
    "# extras=[]\n",
    "# all_sq_braqs=[]\n",
    "# all_carrots=[]\n",
    "\n",
    "# for line in text:\n",
    "    \n",
    "#     line_extras=[]\n",
    "#     sq_bra_each_line=[]\n",
    "#     car_each_line=[]\n",
    "    \n",
    "#     # skipping lines that are not speech \n",
    "#     if line.startswith(\"\\r\\n{\")==False:\n",
    "        \n",
    "#         if \"<\" in line: # others' speech, laughter, \"inaudible\"\n",
    "#             CARROTS_INDEX=[]\n",
    "#             END_CARROTS_INDEX=[]\n",
    "#             for y in line:\n",
    "#                 if y == \"<\":\n",
    "#                     CARROTS_INDEX.append(line.index(y))\n",
    "#                 elif y == \">\":\n",
    "#                     END_CARROTS_INDEX.append(line.index(y))\n",
    "#             for z in CARROTS_INDEX:\n",
    "#                 car=line[z+1:END_CARROTS_INDEX[CARROTS_INDEX.index(z)]]\n",
    "#                 car_each_line.append(car)\n",
    "\n",
    "#         else:\n",
    "#             car_each_line.append(\"Nan\")\n",
    "            \n",
    "#         all_carrots.append(car_each_line)        \n",
    "     \n",
    "#         if \"{\" in line: # spelling corrections, interruptions to the program (I tried to remove previously)\n",
    "#             BRAQ_INDEX=[]\n",
    "#             END_SQ_BRAQ_INDEX=[]\n",
    "#             for y in line:\n",
    "#                 if y == \"{\":\n",
    "#                     BRAQ_INDEX.append(line.index(y))\n",
    "#                 elif y == \"}\":\n",
    "#                     END_SQ_BRAQ_INDEX.append(line.index(y))\n",
    "#             for z in BRAQ_INDEX:\n",
    "#                 sq_bra=line[z+1:END_SQ_BRAQ_INDEX[BRAQ_INDEX.index(z)]]\n",
    "#                 sq_bra_each_line.append(sq_bra)\n",
    "                \n",
    "#         else: \n",
    "#             sq_bra_each_line.append(\"Nan\")\n",
    "            \n",
    "# #         print(sq_bra_each_line)\n",
    "#         all_sq_braqs.append(sq_bra_each_line)\n",
    "# #         print(all_sq_braqs)\n",
    "        \n",
    "# #         if \"[\" in line:\n",
    "# #             bracket=line.index(\"[\")\n",
    "# #             if \"]\" not in line:         \n",
    "# #                 print(line)\n",
    "# #                 print(text.index(line))    # 3093\n",
    "# #             end_bracket=line.index(\"]\")\n",
    "# #             bra=line[bracket:end_bracket]\n",
    "# #             line_extras.append(bra)\n",
    "\n",
    "# #         if \"[\" not in line and \"{\" not in line and \"<\" not in line:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sq_braqs[:10]\n",
    "# text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking which lists are which for my next loop: finding the number of turns per speaker\n",
    "len(line_fid)\n",
    "len(utterance_num)\n",
    "len(new_speaker_list)\n",
    "len(unique_speaker)\n",
    "\n",
    "# these 2 should not line up, just taking a peak at both\n",
    "print(\"Unique Speaker List: length\",str(len(unique_speaker)))\n",
    "unique_speaker[:10]\n",
    "print(\"New Speaker List for each line: length\",str(len(new_speaker_list)))\n",
    "new_speaker_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'NAT4-C33b' in unique_speaker\n",
    "# successfully got the letters to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding number of turns per speaker\n",
    "speaker_counts={}\n",
    "speaker_counts_L=[]\n",
    "for x in unique_speaker:\n",
    "    count=0\n",
    "\n",
    "    for y in new_speaker_list: # remember: new speaker list is the new speaker list for each line of the data\n",
    "        if x==y:\n",
    "            count+=1\n",
    "    speaker_counts[x]=count\n",
    "    speaker_counts_L.append(int(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_speaker)\n",
    "\n",
    "len(speaker_counts)  # why 6 short?\n",
    "len(speaker_counts_L)\n",
    "\n",
    "# because there are duplicates in unique_speaker!!!\n",
    "len(set(unique_speaker)) #length is 421 instead of 428\n",
    "# This means that Simon Marnie is not the only duplicate speaker. I need to \n",
    "# analyze unique_speaker to find duplicates and adjust my loops from above. \n",
    "\n",
    "speaker_counts_L[:100]\n",
    "# Originally two people talked 2678 times, I fixed that issue\n",
    "\n",
    "len(speaker_infos)\n",
    "\n",
    "unique_speaker[:100]\n",
    "\n",
    "unique_speaker[0]\n",
    "unique_speaker[15] # Simon Marnie is P1 for ABCE1 and ABCE2\n",
    "speaker_infos[0]\n",
    "speaker_infos[15] \n",
    "\n",
    "speaker_infos[:17]\n",
    "unique_speaker[:17]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_counts_L[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames\n",
    "### Text DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text DataFrame\n",
    "art_df = pd.DataFrame(new_speaker_list)\n",
    "art_df.head()\n",
    "\n",
    "art_df.columns = [\"Speaker\"]\n",
    "art_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_df[\"Utterance_Number\"]=pd.DataFrame(utterance_num)\n",
    "art_df[\"Text\"]=pd.DataFrame(text)\n",
    "art_df.head()\n",
    "art_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to do multi-level indexing\n",
    "help(art_df.set_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the index to the speaker and utterance number\n",
    "art_df = art_df.set_index(keys=[\"Speaker\",\"Utterance_Number\"])\n",
    "art_df.head()\n",
    "art_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker DataFrame\n",
    "speaker_df = pd.DataFrame(unique_speaker)\n",
    "speaker_df.head()\n",
    "\n",
    "speaker_df.columns = [\"Filename_Speaker\"]\n",
    "speaker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df[\"Speaker_Type\"]=pd.DataFrame(unique_speaker_type) # is this right? investigate later\n",
    "speaker_df[\"Gender\"]=pd.DataFrame(gen)\n",
    "speaker_df[\"Turns\"] = pd.DataFrame(speaker_counts_L)\n",
    "speaker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df = speaker_df.set_index(\"Filename_Speaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df.head()\n",
    "\n",
    "# I have filename_speaker, speaker type, and gender\n",
    "# I added number of lines or \"turns\" <-- this might need editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(speaker_df)\n",
    "speaker_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speaker_counts_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of presenters\n",
    "P_df=speaker_df.loc[speaker_df[\"Speaker_Type\"]=='P',:]\n",
    "P_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of callers\n",
    "C_df=speaker_df.loc[speaker_df[\"Speaker_Type\"]=='C',:]\n",
    "C_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of experts\n",
    "E_df=speaker_df.loc[speaker_df[\"Speaker_Type\"]=='E',:]\n",
    "E_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_df.info()\n",
    "C_df.info()\n",
    "E_df.info()\n",
    "\n",
    "# There are a lot more Callers than there are Presenters and Experts, but there are about equal numbers of Presenters and Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the Presenter DF\n",
    "P_df.max() # 2677\n",
    "P_df.min() # 1\n",
    "P_df.sum() # 3490\n",
    "# help(P_df[\"Turns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_df.describe()\n",
    "C_df.describe()\n",
    "E_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot more callers than there are presenters and experts.\n",
    "This means that the presenters and experts are probably more comparable. However, this will depend on the number of words that are actually uttered by the presenters vs. experts.\n",
    "On average, presenters take about 109.06 turns. However, there is a very high standard deviation of 485. I believe that this is\n",
    "because Simon Marnie talks a lot and is in 2 files. Experts had on average 65.97 turns, but also had a high standard deviation of about 329. \n",
    "The max for presenters (Simon Marnie) was 2677 and for experts it was 1955. These are outliers and are skewing the data.\n",
    "In radio show talks, callers typically are only on the air for a minute or two. This explains why there are so many callers\n",
    "with such low numbers of turns. On average, callers had almost 9 turns. The standard deviation is much lower, partially due to the large number of callers. The max, 230, still seems very high for callers and this may also be an outlier. \n",
    "\n",
    "\n",
    "Based on this corpus, the presenters (the show's hosts) take the most number of turns throughout the show.\n",
    "\n",
    "\n",
    "As for who actually talks the most, I will be looking into that in my next analsis, which will involve word and sentence tokens.\n",
    "\n",
    "\n",
    "Similarly, I will do an analysis on vocabulary size and sentence length to compare across types of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
